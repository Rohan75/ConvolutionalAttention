{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "ModelBuilder.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNwXeEFCjLjU"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cORRd0BKjLjW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import numpy as np\n",
        "import requests as rq\n",
        "import io, h5py"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP5SXKhMjLjX"
      },
      "source": [
        "# Retrieve Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVTZwAPjLjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc564b87-9e8e-4a9b-c3cb-aea85ff423ed"
      },
      "source": [
        "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
        "data.raise_for_status()\n",
        "\n",
        "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
        "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
        "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
        "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_test = np.array(dataset['Y_test']).astype(np.int32)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21000, 200, 4) (21000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq8SRFhPjLjY"
      },
      "source": [
        "# Connect to Drive (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ1WgkFPjLjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c3972d-b0f3-4f46-b991-6a880981fce4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2_xcPd5jLjZ"
      },
      "source": [
        "# Construct Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF1C8iHGjLja"
      },
      "source": [
        "def build_model(params):\n",
        "    # Hyperparameters\n",
        "    filters, kernel_size, batch_norm_1, pool_size, dropout_1, pos_encoding, heads, key_size, dropout_2, dense_size, batch_norm_2, dropout_3 = params\n",
        "    \n",
        "    # Input Layer\n",
        "    inputs = layers.Input(shape=(200, 4))\n",
        "    \n",
        "    # Convolution Block\n",
        "    nn = layers.Conv1D(filters=filters, kernel_size=kernel_size, use_bias=False, padding='same')(inputs)\n",
        "    if batch_norm_1:\n",
        "        nn = layers.BatchNormalization()(nn)\n",
        "    nn = layers.Activation('relu')(nn)\n",
        "    nn = layers.MaxPool1D(pool_size=pool_size)(nn)\n",
        "    if dropout_1 != 0:\n",
        "        nn = layers.Dropout(dropout_1)(nn)\n",
        "    \n",
        "    # Multi-Head Attention Block\n",
        "    if pos_encoding:\n",
        "        positions = tf.range(nn.shape[1])\n",
        "        context = layers.Embedding(input_dim=nn.shape[1], output_dim=nn.shape[2])(positions)\n",
        "        nn = tf.add(nn, context)  # contextual meaning\n",
        "\n",
        "    attention, weights = layers.MultiHeadAttention(num_heads=heads, key_dim=key_size)(nn, nn, return_attention_scores=True)\n",
        "    if dropout_2 != 0:\n",
        "        nn = layers.Dropout(dropout_2)(attention)\n",
        "    nn = layers.LayerNormalization()(nn)\n",
        "    \n",
        "    # Dense Block\n",
        "    nn = layers.Flatten()(nn)\n",
        "    nn = layers.Dense(dense_size, use_bias=False)(nn)\n",
        "    if batch_norm_2:\n",
        "        nn = layers.BatchNormalization()(nn)\n",
        "    nn = layers.Activation('relu')(nn)\n",
        "    if dropout_3 != 0:\n",
        "        nn = layers.Dropout(dropout_3)(nn)\n",
        "    \n",
        "    # Outputs\n",
        "    outputs = layers.Dense(12, activation='sigmoid')(nn)\n",
        "    \n",
        "    # Build Model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.0005), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(curve='ROC', name='auroc'), tf.keras.metrics.AUC(curve='PR', name='aupr')])\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGqDkh8CjLjb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2f0be42-6362-44b8-8354-279c6f9ad8e6"
      },
      "source": [
        "# filters, kernel_size, batch_norm_1, pool_size, dropout_1, pos_encoding, heads, key_size,\n",
        "# dropout_2, dense_size, batch_norm_2, dropout_3\n",
        "base1 = [32, 19, True, 4, 0.1, False, 8, 64, 0.1, 512, True, 0.5]\n",
        "base2 = [32, 19, True, 4, 0.1, False, 8, 64, 0.1, 512, True, 0.5]\n",
        "\n",
        "# Alternate parameters\n",
        "filters = [32, 128, 256]\n",
        "kernels = [19]\n",
        "batch_norm_1 = [True, False]\n",
        "pools = [1, 4, 10, 20]\n",
        "dropout_1 = [0.1, 0.5]\n",
        "pos_encodings = [True, False]\n",
        "heads = [1, 8, 16]\n",
        "keys = [32, 64, 128, 256]\n",
        "dropout_2 = [0.1, 0.5]\n",
        "denses = [64, 256, 512]\n",
        "batch_norm_2 = [True, False]\n",
        "dropout_3 = [0.1, 0.5]\n",
        "\n",
        "names = ['filters', 'kernels', 'batch_norm_1', 'pools', 'dropout_1', 'pos_encodings', 'heads', 'keys', 'dropout_2', 'denses', 'batch_norm_2', 'dropout_3']\n",
        "params = [filters, kernels, batch_norm_1, pools, dropout_1, pos_encodings, heads, keys, dropout_2, denses, batch_norm_2, dropout_3]\n",
        "\n",
        "model = build_model(base1)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_aupr', patience=15, verbose=1, mode='max', restore_best_weights=False)\n",
        "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patience=5, min_lr=1e-7, mode='max', verbose=1) \n",
        "\n",
        "model.fit(x=x_train, y=y_train, epochs=75, validation_data=(x_valid, y_valid), callbacks=[early_stop, lr_decay])\n",
        "model.save(r'/content/drive/MyDrive/model-test')\n",
        "\n",
        "\"\"\"for i in range(len(params)):\n",
        "    for j in range(len(params[i])):\n",
        "        direc = names[i]\n",
        "        name = f'model-{params[i][j]}'\n",
        "        \n",
        "        args = base1.copy()\n",
        "        args[i] = params[i][j]\n",
        "        \n",
        "        model = build_model(args)\n",
        "        \n",
        "        # Callbacks\n",
        "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_aupr', patience=15, verbose=1, mode='max', restore_best_weights=False)\n",
        "        lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patience=5, min_lr=1e-7, mode='max', verbose=1) \n",
        "        tensorboard = tf.keras.callbacks.Tensorboard(log_dir=f'/content/drive/MyDrive/ColabNotebooks/ConvAttTests/logs/{direc}/{name}')\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/ColabNotebooks/ConvAttTets/models/{direc}/{name}')\n",
        "        \n",
        "        model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_valid, y_valid), callbacks=[early_stop, lr_decay, tensorboard, checkpoint])\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "657/657 [==============================] - 8s 9ms/step - loss: 0.5014 - auroc: 0.5302 - aupr: 0.1686 - val_loss: 0.6624 - val_auroc: 0.6607 - val_aupr: 0.3735\n",
            "Epoch 2/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.3581 - auroc: 0.7289 - aupr: 0.4312 - val_loss: 0.3229 - val_auroc: 0.8166 - val_aupr: 0.5419\n",
            "Epoch 3/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.3106 - auroc: 0.8092 - aupr: 0.5546 - val_loss: 0.2876 - val_auroc: 0.8594 - val_aupr: 0.6336\n",
            "Epoch 4/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2815 - auroc: 0.8515 - aupr: 0.6298 - val_loss: 0.2647 - val_auroc: 0.8821 - val_aupr: 0.6869\n",
            "Epoch 5/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2662 - auroc: 0.8707 - aupr: 0.6678 - val_loss: 0.2372 - val_auroc: 0.9071 - val_aupr: 0.7337\n",
            "Epoch 6/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2550 - auroc: 0.8829 - aupr: 0.6918 - val_loss: 0.2469 - val_auroc: 0.9017 - val_aupr: 0.7325\n",
            "Epoch 7/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2402 - auroc: 0.8986 - aupr: 0.7242 - val_loss: 0.2354 - val_auroc: 0.9202 - val_aupr: 0.7683\n",
            "Epoch 8/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2277 - auroc: 0.9105 - aupr: 0.7549 - val_loss: 0.2190 - val_auroc: 0.9392 - val_aupr: 0.8054\n",
            "Epoch 9/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.2184 - auroc: 0.9178 - aupr: 0.7721 - val_loss: 0.2161 - val_auroc: 0.9380 - val_aupr: 0.8053\n",
            "Epoch 10/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.2117 - auroc: 0.9224 - aupr: 0.7836 - val_loss: 0.2171 - val_auroc: 0.9361 - val_aupr: 0.7908\n",
            "Epoch 11/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.2088 - auroc: 0.9272 - aupr: 0.7884 - val_loss: 0.1962 - val_auroc: 0.9485 - val_aupr: 0.8300\n",
            "Epoch 12/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.2033 - auroc: 0.9294 - aupr: 0.7961 - val_loss: 0.2111 - val_auroc: 0.9348 - val_aupr: 0.8082\n",
            "Epoch 13/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2005 - auroc: 0.9317 - aupr: 0.8029 - val_loss: 0.1938 - val_auroc: 0.9515 - val_aupr: 0.8407\n",
            "Epoch 14/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1964 - auroc: 0.9346 - aupr: 0.8088 - val_loss: 0.2123 - val_auroc: 0.9363 - val_aupr: 0.8066\n",
            "Epoch 15/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1953 - auroc: 0.9361 - aupr: 0.8127 - val_loss: 0.1889 - val_auroc: 0.9486 - val_aupr: 0.8357\n",
            "Epoch 16/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1945 - auroc: 0.9364 - aupr: 0.8137 - val_loss: 0.1910 - val_auroc: 0.9512 - val_aupr: 0.8407\n",
            "Epoch 17/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1913 - auroc: 0.9381 - aupr: 0.8199 - val_loss: 0.1940 - val_auroc: 0.9446 - val_aupr: 0.8291\n",
            "Epoch 18/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1896 - auroc: 0.9395 - aupr: 0.8219 - val_loss: 0.1922 - val_auroc: 0.9443 - val_aupr: 0.8283\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 19/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1809 - auroc: 0.9444 - aupr: 0.8368 - val_loss: 0.1762 - val_auroc: 0.9543 - val_aupr: 0.8529\n",
            "Epoch 20/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1811 - auroc: 0.9450 - aupr: 0.8343 - val_loss: 0.1743 - val_auroc: 0.9563 - val_aupr: 0.8557\n",
            "Epoch 21/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1784 - auroc: 0.9461 - aupr: 0.8379 - val_loss: 0.1746 - val_auroc: 0.9562 - val_aupr: 0.8558\n",
            "Epoch 22/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1795 - auroc: 0.9457 - aupr: 0.8373 - val_loss: 0.1729 - val_auroc: 0.9578 - val_aupr: 0.8613\n",
            "Epoch 23/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1789 - auroc: 0.9453 - aupr: 0.8375 - val_loss: 0.1745 - val_auroc: 0.9555 - val_aupr: 0.8552\n",
            "Epoch 24/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1771 - auroc: 0.9475 - aupr: 0.8439 - val_loss: 0.1714 - val_auroc: 0.9581 - val_aupr: 0.8612\n",
            "Epoch 25/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.1738 - auroc: 0.9495 - aupr: 0.8446 - val_loss: 0.1757 - val_auroc: 0.9552 - val_aupr: 0.8522\n",
            "Epoch 26/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1761 - auroc: 0.9472 - aupr: 0.8448 - val_loss: 0.1694 - val_auroc: 0.9586 - val_aupr: 0.8624\n",
            "Epoch 27/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1750 - auroc: 0.9480 - aupr: 0.8448 - val_loss: 0.1726 - val_auroc: 0.9560 - val_aupr: 0.8592\n",
            "Epoch 28/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1765 - auroc: 0.9478 - aupr: 0.8430 - val_loss: 0.1757 - val_auroc: 0.9547 - val_aupr: 0.8564\n",
            "Epoch 29/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1743 - auroc: 0.9488 - aupr: 0.8474 - val_loss: 0.1745 - val_auroc: 0.9564 - val_aupr: 0.8600\n",
            "Epoch 30/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1746 - auroc: 0.9487 - aupr: 0.8497 - val_loss: 0.1772 - val_auroc: 0.9538 - val_aupr: 0.8524\n",
            "Epoch 31/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.1710 - auroc: 0.9505 - aupr: 0.8508 - val_loss: 0.1780 - val_auroc: 0.9551 - val_aupr: 0.8545\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
            "Epoch 32/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1716 - auroc: 0.9499 - aupr: 0.8501 - val_loss: 0.1734 - val_auroc: 0.9563 - val_aupr: 0.8579\n",
            "Epoch 33/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1714 - auroc: 0.9505 - aupr: 0.8495 - val_loss: 0.1741 - val_auroc: 0.9562 - val_aupr: 0.8583\n",
            "Epoch 34/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1728 - auroc: 0.9496 - aupr: 0.8503 - val_loss: 0.1749 - val_auroc: 0.9558 - val_aupr: 0.8568\n",
            "Epoch 35/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1721 - auroc: 0.9507 - aupr: 0.8525 - val_loss: 0.1742 - val_auroc: 0.9562 - val_aupr: 0.8580\n",
            "Epoch 36/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.1707 - auroc: 0.9507 - aupr: 0.8522 - val_loss: 0.1754 - val_auroc: 0.9555 - val_aupr: 0.8562\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
            "Epoch 37/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1720 - auroc: 0.9495 - aupr: 0.8514 - val_loss: 0.1736 - val_auroc: 0.9564 - val_aupr: 0.8585\n",
            "Epoch 38/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1694 - auroc: 0.9513 - aupr: 0.8524 - val_loss: 0.1741 - val_auroc: 0.9561 - val_aupr: 0.8579\n",
            "Epoch 39/75\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1686 - auroc: 0.9524 - aupr: 0.8552 - val_loss: 0.1750 - val_auroc: 0.9557 - val_aupr: 0.8574\n",
            "Epoch 40/75\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.1702 - auroc: 0.9519 - aupr: 0.8523 - val_loss: 0.1746 - val_auroc: 0.9559 - val_aupr: 0.8577\n",
            "Epoch 41/75\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.1719 - auroc: 0.9508 - aupr: 0.8523 - val_loss: 0.1736 - val_auroc: 0.9562 - val_aupr: 0.8583\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 8.000000889296644e-07.\n",
            "Epoch 00041: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model-test/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model-test/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"for i in range(len(params)):\\n    for j in range(len(params[i])):\\n        direc = names[i]\\n        name = f'model-{params[i][j]}'\\n        \\n        args = base1.copy()\\n        args[i] = params[i][j]\\n        \\n        model = build_model(args)\\n        \\n        # Callbacks\\n        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_aupr', patience=15, verbose=1, mode='max', restore_best_weights=False)\\n        lr_decay = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_aupr', factor=0.2, patience=5, min_lr=1e-7, mode='max', verbose=1) \\n        tensorboard = tf.keras.callbacks.Tensorboard(log_dir=f'/content/drive/MyDrive/ColabNotebooks/ConvAttTests/logs/{direc}/{name}')\\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/ColabNotebooks/ConvAttTets/models/{direc}/{name}')\\n        \\n        model.fit(x=x_train, y=y_train, epochs=10, validation_data=(x_valid, y_valid), callbacks=[early_stop, lr_decay, tensorboard, checkpoint])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}