{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "import io, h5py\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
    "data.raise_for_status()\n",
    "\n",
    "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(h5py.File(r'models/model.h5', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 25ms/step - loss: 0.1708 - auroc: 0.9589 - aupr: 0.8613\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 200, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 200, 32)      2432        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 200, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 200, 32)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 50, 32)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 50, 32)       0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe ((None, 50, 32), (No 67104       dropout_24[0][0]                 \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 50, 32)       0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 50, 32)       64          dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1600)         0           layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 512)          819200      flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512)          2048        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 512)          0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 12)           6156        dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 897,132\n",
      "Trainable params: 896,044\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-3506c296a736>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  ppms = np.array(ppms)\n"
     ]
    }
   ],
   "source": [
    "layer = 3        # activation layer for 1st convolutional layer\n",
    "threshold = 0.5  # threshold for significant activations\n",
    "window = 20      # window size of alignment \n",
    "\n",
    "# get feature maps of 1st convolutional layer after activation\n",
    "intermediate = tf.keras.Model(inputs=model.inputs, outputs=model.layers[layer].output)\n",
    "fmap = intermediate.predict(x_test)\n",
    "num_filters = fmap.shape[-1]\n",
    "\n",
    "# set the left and right window sizes\n",
    "window_left = int(window/2)\n",
    "window_right = window - window_left\n",
    "\n",
    "N, L, A = x_test.shape\n",
    "\n",
    "ppms = []\n",
    "for filter_index in range(num_filters):\n",
    "\n",
    "    # find regions above threshold\n",
    "    coords = np.where(fmap[:,:,filter_index] > np.max(fmap[:,:,filter_index])*threshold)\n",
    "    x, y = coords\n",
    "\n",
    "    # sort score\n",
    "    index = np.argsort(fmap[x,y,filter_index])[::-1]\n",
    "    data_index = x[index].astype(int)\n",
    "    pos_index = y[index].astype(int)\n",
    "\n",
    "    # make a sequence alignment centered about each activation (above threshold)\n",
    "    seq_align = []\n",
    "    for i in range(len(pos_index)):\n",
    "\n",
    "        # determine position of window about each filter activation\n",
    "        start_window = pos_index[i] - window_left\n",
    "        end_window = pos_index[i] + window_right\n",
    "\n",
    "        # check to make sure positions are valid\n",
    "        if (start_window > 0) & (end_window < L):\n",
    "            seq = x_test[data_index[i], start_window:end_window, :]\n",
    "            seq_align.append(seq)\n",
    "\n",
    "    # calculate position probability matrix\n",
    "    \n",
    "    ppm = np.mean(seq_align, axis=0)\n",
    "    \n",
    "    # splice positions with uniform probability\n",
    "    x, y = np.where(ppm > 0.4)\n",
    "    low = max(x[0]-1, 0)\n",
    "    high = min(x[-1]+1, ppm.shape[0])\n",
    "    ppm = ppm[low:high]\n",
    "    \n",
    "    ppms.append(ppm)\n",
    "ppms = np.array(ppms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ppms.shape[0]):\n",
    "    open(f'motifs/model-test/filter-{i+1}.txt', 'w+').close()\n",
    "\n",
    "    motif = ppms[i]\n",
    "    out = []\n",
    "\n",
    "    out.append(\"MEME version 4\\n\\n\")\n",
    "\n",
    "    out.append(\"ALPHABET= ACGT\\n\\n\")\n",
    "\n",
    "    out.append(\"strands: + -\\n\\n\")\n",
    "\n",
    "    out.append(\"Background letter frequencies\\n\")\n",
    "    out.append(\"A 0.25 C 0.25 G 0.25 T 0.25\\n\\n\")\n",
    "\n",
    "    out.append(f\"MOTIF filter-{i+1}\\n\")\n",
    "    out.append(f\"letter-probability matrix: alength= 4 w= {ppms[i].shape[0]}\\n\")\n",
    "\n",
    "    for j in motif:\n",
    "        out.append(\"%.4f %.4f %.4f %.4f\\n\" % (j[0], j[1], j[2], j[3]))\n",
    "\n",
    "    with open(f'motifs/model-test/filter-{i+1}.txt', 'w') as file:\n",
    "        file.writelines(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
