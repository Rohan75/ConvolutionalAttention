{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GwUSIzFCDo0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import numpy as np\n",
        "import requests as rq\n",
        "import io, h5py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40FDKDrCDo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873ff68a-df10-40e8-d9f7-b733f491e90b"
      },
      "source": [
        "data = rq.get('https://www.dropbox.com/s/c3umbo5y13sqcfp/synthetic_dataset.h5?raw=true')\n",
        "data.raise_for_status()\n",
        "\n",
        "with h5py.File(io.BytesIO(data.content), 'r') as dataset:\n",
        "    x_train = np.array(dataset['X_train']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
        "    x_valid = np.array(dataset['X_valid']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
        "    x_test = np.array(dataset['X_test']).astype(np.float32).transpose([0, 2, 1])\n",
        "    y_test = np.array(dataset['Y_test']).astype(np.int32)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21000, 200, 4) (21000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccCeov6oObuI"
      },
      "source": [
        "def generate_model(p):\r\n",
        "  input_layer = layers.Input(shape=(200, 4))\r\n",
        "\r\n",
        "  conv1 = layers.Conv1D(filters=64, kernel_size=13, padding='same', use_bias='false')(input_layer)\r\n",
        "  BN1 = layers.BatchNormalization()(conv1)\r\n",
        "  relu1 = layers.Activation('relu')(BN1)\r\n",
        "  pool1 = layers.MaxPool1D(pool_size=p)(relu1)\r\n",
        "  drop1 = layers.Dropout(0.05)(pool1)\r\n",
        "\r\n",
        "  positions = tf.range(drop1.shape[1])\r\n",
        "  context = layers.Embedding(input_dim=drop1.shape[1], output_dim=drop1.shape[2])(positions)\r\n",
        "\r\n",
        "  contextual_meaning = tf.add(drop1, context)\r\n",
        "\r\n",
        "  query = layers.Dense(100, name='query')(contextual_meaning)\r\n",
        "  value = layers.Dense(100)(contextual_meaning)\r\n",
        "\r\n",
        "  attention, weights = layers.MultiHeadAttention(num_heads=8, key_dim=32, dropout=0.55)(query, value, return_attention_scores=True)\r\n",
        "\r\n",
        "  flat = layers.Flatten()(attention)\r\n",
        "  fcl = layers.Dense(512, activation='relu')(flat)\r\n",
        "  BN2 = layers.BatchNormalization()(fcl)\r\n",
        "  relu2 = layers.Activation('relu')(BN2)\r\n",
        "  drop2 = layers.Dropout(0.5)(fcl)\r\n",
        "\r\n",
        "  output = layers.Dense(12, activation='sigmoid')(drop2)\r\n",
        "\r\n",
        "  model = Model(inputs=input_layer, outputs=output)\r\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC(curve='ROC', name='auroc'), tf.keras.metrics.AUC(curve='PR', name='aupr')])\r\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JAqmnFAnCDo6",
        "outputId": "41dbf762-94be-4815-d9fb-ee86af6a7c02"
      },
      "source": [
        "model = generate_model(10)\n",
        "model.fit(x_train, y_train, epochs=60, validation_data=(x_valid, y_valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "657/657 [==============================] - 7s 9ms/step - loss: 0.5113 - auroc: 0.5175 - aupr: 0.1512 - val_loss: 0.5085 - val_auroc: 0.5761 - val_aupr: 0.2050\n",
            "Epoch 2/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.4201 - auroc: 0.6091 - aupr: 0.2381 - val_loss: 0.3887 - val_auroc: 0.6816 - val_aupr: 0.3254\n",
            "Epoch 3/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.3842 - auroc: 0.6905 - aupr: 0.3532 - val_loss: 0.3207 - val_auroc: 0.8053 - val_aupr: 0.5280\n",
            "Epoch 4/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.3356 - auroc: 0.7806 - aupr: 0.5019 - val_loss: 0.2721 - val_auroc: 0.8637 - val_aupr: 0.6402\n",
            "Epoch 5/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.3045 - auroc: 0.8256 - aupr: 0.5805 - val_loss: 0.2561 - val_auroc: 0.8819 - val_aupr: 0.6803\n",
            "Epoch 6/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2862 - auroc: 0.8522 - aupr: 0.6293 - val_loss: 0.2306 - val_auroc: 0.9095 - val_aupr: 0.7373\n",
            "Epoch 7/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2703 - auroc: 0.8724 - aupr: 0.6674 - val_loss: 0.2208 - val_auroc: 0.9195 - val_aupr: 0.7607\n",
            "Epoch 8/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2554 - auroc: 0.8869 - aupr: 0.6965 - val_loss: 0.2061 - val_auroc: 0.9308 - val_aupr: 0.7896\n",
            "Epoch 9/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2468 - auroc: 0.8947 - aupr: 0.7159 - val_loss: 0.2000 - val_auroc: 0.9337 - val_aupr: 0.7989\n",
            "Epoch 10/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2381 - auroc: 0.9021 - aupr: 0.7296 - val_loss: 0.2085 - val_auroc: 0.9343 - val_aupr: 0.7906\n",
            "Epoch 11/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2331 - auroc: 0.9076 - aupr: 0.7402 - val_loss: 0.1966 - val_auroc: 0.9390 - val_aupr: 0.8033\n",
            "Epoch 12/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2292 - auroc: 0.9116 - aupr: 0.7541 - val_loss: 0.1894 - val_auroc: 0.9424 - val_aupr: 0.8162\n",
            "Epoch 13/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2243 - auroc: 0.9154 - aupr: 0.7593 - val_loss: 0.1961 - val_auroc: 0.9405 - val_aupr: 0.8036\n",
            "Epoch 14/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2216 - auroc: 0.9183 - aupr: 0.7685 - val_loss: 0.1856 - val_auroc: 0.9467 - val_aupr: 0.8259\n",
            "Epoch 15/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2156 - auroc: 0.9222 - aupr: 0.7757 - val_loss: 0.1886 - val_auroc: 0.9451 - val_aupr: 0.8214\n",
            "Epoch 16/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2163 - auroc: 0.9231 - aupr: 0.7768 - val_loss: 0.1812 - val_auroc: 0.9485 - val_aupr: 0.8288\n",
            "Epoch 17/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2157 - auroc: 0.9232 - aupr: 0.7777 - val_loss: 0.1812 - val_auroc: 0.9488 - val_aupr: 0.8328\n",
            "Epoch 18/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2122 - auroc: 0.9254 - aupr: 0.7829 - val_loss: 0.1895 - val_auroc: 0.9441 - val_aupr: 0.8150\n",
            "Epoch 19/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2128 - auroc: 0.9246 - aupr: 0.7846 - val_loss: 0.1753 - val_auroc: 0.9529 - val_aupr: 0.8419\n",
            "Epoch 20/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2082 - auroc: 0.9276 - aupr: 0.7895 - val_loss: 0.1734 - val_auroc: 0.9537 - val_aupr: 0.8421\n",
            "Epoch 21/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2060 - auroc: 0.9292 - aupr: 0.7929 - val_loss: 0.1779 - val_auroc: 0.9501 - val_aupr: 0.8356\n",
            "Epoch 22/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2050 - auroc: 0.9304 - aupr: 0.7952 - val_loss: 0.1763 - val_auroc: 0.9520 - val_aupr: 0.8378\n",
            "Epoch 23/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.2019 - auroc: 0.9327 - aupr: 0.7998 - val_loss: 0.1771 - val_auroc: 0.9526 - val_aupr: 0.8397\n",
            "Epoch 24/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1999 - auroc: 0.9334 - aupr: 0.8026 - val_loss: 0.1703 - val_auroc: 0.9566 - val_aupr: 0.8480\n",
            "Epoch 25/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.1987 - auroc: 0.9346 - aupr: 0.8028 - val_loss: 0.1711 - val_auroc: 0.9546 - val_aupr: 0.8465\n",
            "Epoch 26/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.2009 - auroc: 0.9331 - aupr: 0.8033 - val_loss: 0.1684 - val_auroc: 0.9573 - val_aupr: 0.8493\n",
            "Epoch 27/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1985 - auroc: 0.9361 - aupr: 0.8081 - val_loss: 0.1786 - val_auroc: 0.9497 - val_aupr: 0.8331\n",
            "Epoch 28/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1953 - auroc: 0.9372 - aupr: 0.8120 - val_loss: 0.1683 - val_auroc: 0.9569 - val_aupr: 0.8500\n",
            "Epoch 29/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1958 - auroc: 0.9364 - aupr: 0.8109 - val_loss: 0.1639 - val_auroc: 0.9599 - val_aupr: 0.8597\n",
            "Epoch 30/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1961 - auroc: 0.9375 - aupr: 0.8113 - val_loss: 0.1656 - val_auroc: 0.9575 - val_aupr: 0.8543\n",
            "Epoch 31/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1952 - auroc: 0.9379 - aupr: 0.8127 - val_loss: 0.1678 - val_auroc: 0.9566 - val_aupr: 0.8535\n",
            "Epoch 32/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1916 - auroc: 0.9397 - aupr: 0.8182 - val_loss: 0.1757 - val_auroc: 0.9529 - val_aupr: 0.8395\n",
            "Epoch 33/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.1919 - auroc: 0.9391 - aupr: 0.8147 - val_loss: 0.1719 - val_auroc: 0.9569 - val_aupr: 0.8476\n",
            "Epoch 34/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1894 - auroc: 0.9414 - aupr: 0.8226 - val_loss: 0.1641 - val_auroc: 0.9599 - val_aupr: 0.8544\n",
            "Epoch 35/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1914 - auroc: 0.9408 - aupr: 0.8193 - val_loss: 0.1631 - val_auroc: 0.9606 - val_aupr: 0.8612\n",
            "Epoch 36/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1897 - auroc: 0.9413 - aupr: 0.8224 - val_loss: 0.1635 - val_auroc: 0.9595 - val_aupr: 0.8553\n",
            "Epoch 37/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1864 - auroc: 0.9427 - aupr: 0.8264 - val_loss: 0.1637 - val_auroc: 0.9618 - val_aupr: 0.8641\n",
            "Epoch 38/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1863 - auroc: 0.9433 - aupr: 0.8257 - val_loss: 0.1743 - val_auroc: 0.9564 - val_aupr: 0.8512\n",
            "Epoch 39/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1866 - auroc: 0.9434 - aupr: 0.8260 - val_loss: 0.1682 - val_auroc: 0.9566 - val_aupr: 0.8499\n",
            "Epoch 40/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.1861 - auroc: 0.9436 - aupr: 0.8275 - val_loss: 0.1638 - val_auroc: 0.9595 - val_aupr: 0.8550\n",
            "Epoch 41/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1861 - auroc: 0.9434 - aupr: 0.8282 - val_loss: 0.1716 - val_auroc: 0.9576 - val_aupr: 0.8448\n",
            "Epoch 42/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1840 - auroc: 0.9447 - aupr: 0.8300 - val_loss: 0.1592 - val_auroc: 0.9615 - val_aupr: 0.8641\n",
            "Epoch 43/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1846 - auroc: 0.9449 - aupr: 0.8299 - val_loss: 0.1733 - val_auroc: 0.9567 - val_aupr: 0.8511\n",
            "Epoch 44/60\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.1819 - auroc: 0.9458 - aupr: 0.8333 - val_loss: 0.1603 - val_auroc: 0.9617 - val_aupr: 0.8613\n",
            "Epoch 45/60\n",
            "657/657 [==============================] - 5s 7ms/step - loss: 0.1828 - auroc: 0.9453 - aupr: 0.8309 - val_loss: 0.1630 - val_auroc: 0.9609 - val_aupr: 0.8573\n",
            "Epoch 46/60\n",
            "318/657 [=============>................] - ETA: 2s - loss: 0.1824 - auroc: 0.9459 - aupr: 0.8340"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f52d27a1ad56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}